{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "JO8UQtOCzrS1",
    "outputId": "e55c2e24-2154-478f-d546-1fb4698491df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uq1MGoIR6CFz"
   },
   "source": [
    "Haar features for the facial features detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llVZxgbD1GNt"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml -P drive/My\\ Drive\n",
    "# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye_tree_eyeglasses.xml -P drive/My\\ Drive\n",
    "# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml -P drive/My\\ Drive\n",
    "# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml -P drive/My\\ Drive  \n",
    "# !wget https://raw.githubusercontent.com/opencv/opencv_contrib/master/modules/face/data/cascades/haarcascade_mcs_nose.xml -P drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6PBuvXE6NPP"
   },
   "source": [
    "Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_WwaSVD1dBV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ta3firqw6TR6"
   },
   "source": [
    "initialising the cascade haar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqfp-9kw1IuH"
   },
   "outputs": [],
   "source": [
    "cascades_path = 'drive/My Drive/'\n",
    "face_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_eye_tree_eyeglasses.xml')\n",
    "nose_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_mcs_nose.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucyPfKMb6aUz"
   },
   "source": [
    "Face detection function. This one creates the oval shape around the face so that the unnecessary background doesn't come into picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66v-s1iA1RqN"
   },
   "outputs": [],
   "source": [
    "def face_detect(img):\n",
    "  gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "  faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "  if (len(faces) == 0 ):\n",
    "    return None, None\n",
    "  else:\n",
    "    for (x , y, w, h) in faces:\n",
    "      roi_gray = gray[y:y+h, x:x+w]\n",
    "      roi_color = img[y:y+h, x:x+w]\n",
    "      mask = np.zeros_like(roi_color)\n",
    "      img_mask = np.zeros_like(img)\n",
    "      rows, cols,_ = mask.shape\n",
    "      img_mask = cv2.ellipse(img_mask,(int(rows/2)+x, int(cols/2)+y), (int((2*x+w)/3),int((2*y+h)/3.2)), angle=0, startAngle=0, endAngle=360, color=(255,255,255), thickness=-1)    \n",
    "      img = np.bitwise_and(img_mask, img)\n",
    "      img = img[y:y+h, x:x+w]\n",
    "      img_gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "  return img,img_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ykd-cugT6rTu"
   },
   "source": [
    "Reading the dataset images one by one labelling them accordingly. Image is resized to (64, 64) dimension due to memory contraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05JFWGDP1T5X"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "label = []\n",
    "filenames = os.listdir(\"/content/drive/My Drive/AVR_data\")\n",
    "for filename in filenames:\n",
    "  sub_filenames = os.listdir(\"/content/drive/My Drive/AVR_data/\"+filename)\n",
    "  for sub_file in sub_filenames:\n",
    "    image = cv2.imread(\"/content/drive/My Drive/AVR_data/\"+filename + \"/\" +sub_file)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image, image_gray = face_detect(image)\n",
    "    if image is not None:\n",
    "      image_g = cv2.resize(image_gray , (64, 64))\n",
    "      images.append(image_g)\n",
    "      label.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aazrRO4Z7KnV"
   },
   "source": [
    "Completing the labelling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRz02oIi1Vmx"
   },
   "outputs": [],
   "source": [
    "labels = np.array(label)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "enc_labels = label_encoder.fit_transform(labels) \n",
    "labels_unique = label_encoder.classes_\n",
    "labels_unique = np.array(labels_unique)\n",
    "enc_labels = np.array(enc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhutJkvG1oBP"
   },
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-XyMOML7PxT"
   },
   "source": [
    "Flatten the single image from (64, 64) to (4096, 1) and then creating a set of those array by stacking them column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkHAsaOA1qKY"
   },
   "outputs": [],
   "source": [
    "def flatten_array(images):\n",
    "  X_data = []\n",
    "  for image in images:\n",
    "      X_data.append(image.flatten())\n",
    "  X_data = np.array(X_data)\n",
    "  return X_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV8v9c8D7kzR"
   },
   "source": [
    "euclideanDistance function calculates the distance between two vectors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_Lk7JB51rd1"
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(vector1, vector2):\n",
    "  return np.linalg.norm(vector1 - vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66ExYqO28G9J"
   },
   "source": [
    "leastEucDisN first invokes the distance calculation then sorts those distance in ascending order and returns the top N nearest neighbours labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTlp3dje1vbM"
   },
   "outputs": [],
   "source": [
    "def leastEucDistN(matrix, vector, N):\n",
    "    distance_list = []\n",
    "    for i in range(((matrix.T).shape)[0]):\n",
    "        euc_dist = euclideanDistance(vector, (matrix.T)[i]) \n",
    "        distance_list.append([euc_dist, i])\n",
    "    distance_list = sorted(distance_list)\n",
    "    min_ind_list = []\n",
    "    for i in range(N):\n",
    "        min_ind_list.append(distance_list[i][1])\n",
    "    return min_ind_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvuWFuxd8dTk"
   },
   "source": [
    "The sorted labels are then compared with the test label if they are in top N distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vGN0phu1zQB"
   },
   "outputs": [],
   "source": [
    "def PCA_sklearn_predictions(X_train_pca ,y_train, X_test_pca, N):\n",
    "  dist = []\n",
    "  predictions = []\n",
    "  for test_col in X_test_pca:\n",
    "    dist = leastEucDistN(X_train_pca.T, test_col , N)\n",
    "    l2 = []\n",
    "    for i in range(len(dist)):\n",
    "      l2.append(y_train[dist[i]])\n",
    "    predictions.append(l2)\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z19OstUi83og"
   },
   "source": [
    "This function then computes the count of correctly labelled predictions and then returns the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEbLsq232XtS"
   },
   "outputs": [],
   "source": [
    "def PCA_accuracyN(predictions, y_test, N):\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "      if ((y_test[i]) in predictions[i]):\n",
    "        count += 1\n",
    "    print(\"PCA top:\", N, \"Accuracy: \", (count/(len(y_test)-1))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJZIvS7v13QE"
   },
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARccu0UH9Ijs"
   },
   "source": [
    "Image dataset is flattened and stacked column wise. the total images read properly are 624. Some image enhachments are required to read the whole 824 images properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Wb4qtT9O143r",
    "outputId": "655bcfef-043e-4b2a-f0c7-f4866ada3c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 624)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = flatten_array(images)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPArlQ7f9d0P"
   },
   "source": [
    "Splittng the test train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-Jmr_-I17Yl"
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(image.T, enc_labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xY1bgy929qV5"
   },
   "source": [
    "The test train splits the dataset into 468 and 156 images respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "nw91kTna9jES",
    "outputId": "ad868d41-5c0e-412c-9b25-872bfc998875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 4096)\n",
      "(156, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ib92nwJ94ow"
   },
   "source": [
    "Next task is to reduce the dimensions of the images. Since a single image is having the 4096 features, the distance matric will take a lot of time to evaluate and also will include some un necessary features which are not present in all the images. One method is to use **PCA** another method that could be used is **LDA**. Here LDA is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VGUw6Yh2DsR"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbphFfm8hVSw"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_OWn1tM-W8b"
   },
   "source": [
    "After some hit and trial in the number of features. 20 is the best number of features that describes the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzR_p40c2J1x"
   },
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "\n",
    "# apply PCA transformation\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVIZaYHH-w5g"
   },
   "source": [
    "The features are reduced whitout disturbing the image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "nxinqF80-mJQ",
    "outputId": "a350ca2f-7df8-4000-eaee-39bd44072b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 40)\n",
      "(468, 40)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_lda.shape)\n",
    "print(X_train_lda.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKS1xyDP-8DS"
   },
   "source": [
    "These are top N accuracies of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "OsUPXtrt2MCp",
    "outputId": "ecd4c6bc-e091-4674-ebd6-5f435db5d22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA top: 1 Accuracy:  60.64516129032258\n",
      "PCA top: 3 Accuracy:  74.83870967741936\n",
      "PCA top: 5 Accuracy:  80.64516129032258\n",
      "PCA top: 10 Accuracy:  87.09677419354838\n"
     ]
    }
   ],
   "source": [
    "predictions = PCA_sklearn_predictions(X_train_lda, y_train, X_test_lda , 1)\n",
    "PCA_accuracyN(predictions, y_test, 1)\n",
    "predictions = PCA_sklearn_predictions(X_train_lda, y_train, X_test_lda , 3)\n",
    "PCA_accuracyN(predictions, y_test, 3)\n",
    "predictions = PCA_sklearn_predictions(X_train_lda, y_train, X_test_lda , 5)\n",
    "PCA_accuracyN(predictions, y_test, 5)\n",
    "predictions = PCA_sklearn_predictions(X_train_lda, y_train, X_test_lda , 10)\n",
    "PCA_accuracyN(predictions, y_test, 10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face_recog_LDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
